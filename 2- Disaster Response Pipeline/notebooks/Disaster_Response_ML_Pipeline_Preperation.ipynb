{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLTgFyBtgDh0"
      },
      "source": [
        "# ML Pipeline Preperation\n",
        "## *Disaster Response Project*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TyVHZK5mheMx"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2LYO6WpbPC8",
        "outputId": "f9f4326e-3612-497a-8cde-663881b511ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\thr3e\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\thr3e\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\thr3e\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     C:\\Users\\thr3e\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd \n",
        "import re\n",
        "import nltk\n",
        "import pickle\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sqlalchemy import create_engine\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00cw0NTFg0AX"
      },
      "source": [
        "### Static Variables and Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_anSVgcIf4pf"
      },
      "outputs": [],
      "source": [
        "url_regex = 'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTfTpZLug6Lo"
      },
      "source": [
        "### Functions & Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oDZnmtjogAmx"
      },
      "outputs": [],
      "source": [
        "def normalizeUrls(text):\n",
        "  urls = re.findall(url_regex, text)\n",
        "\n",
        "  for url in urls:\n",
        "    text = text.replace(url, 'urlph')\n",
        "\n",
        "  return text "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AU8DDHFohuGf"
      },
      "outputs": [],
      "source": [
        "def tokenize(text):\n",
        "  # remove the punctuations and special characters\n",
        "  text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text).lower().strip()\n",
        "\n",
        "  # tokenize the text\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "  # remove stopwords\n",
        "  tokens = [t for t in tokens if t not in stopwords.words(\"english\")]\n",
        "\n",
        "  # define the lematizer\n",
        "  lemm = WordNetLemmatizer()\n",
        "\n",
        "  # lemmatize words to the base form\n",
        "  tokens = [lemm.lemmatize(t) for t in tokens]\n",
        "\n",
        "  # lematize verbs also to the base form\n",
        "  tokens = [lemm.lemmatize(t, pos=\"v\") for t in tokens]\n",
        "\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8DhdgvDhOB1"
      },
      "source": [
        "### Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqg3Mv4tcszn",
        "outputId": "aa445dca-de3b-4521-b36f-829f945b0d32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26216, 39)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Read database table and convert to dataframe\n",
        "engine = create_engine('sqlite:///disaster.db')\n",
        "df = pd.read_sql(\"SELECT * from messages\", engine)\n",
        "df = df.drop(['original'], axis=1)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8Y1Iy7ZhzrcF"
      },
      "outputs": [],
      "source": [
        "# there are non-binary values at the dataframe, we got errors at classification report :(\n",
        "# - we will copy the dataframe to check binary values\n",
        "df_binary_check = df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zr7Go8cQWl7Q",
        "outputId": "6fc35aec-4cc6-4002-e7e2-2678fef47e34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "related - [1 0 2]\n"
          ]
        }
      ],
      "source": [
        "# get unique values for each column in df_binary_check and see which one is not binary\n",
        "for col in df_binary_check.columns[3:]:\n",
        "  unq = df_binary_check[col].unique()\n",
        "  if np.any((unq > 1) | (unq < 0)):\n",
        "    print(col, \"-\", unq) # we can see the 'related' values are not binary, it does have the values of 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0av9EsOT3QVi",
        "outputId": "1ce2ac7a-0925-4fd9-93a9-bb41fabba278"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26216, 39)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-Cqv5NH_q1me"
      },
      "outputs": [],
      "source": [
        "# for each column, if there are values equal 2, drop the row\n",
        "for col in df.columns[3:]:\n",
        "  df = df[df[col] < 2].dropna()\n",
        "  unq = df[col].unique()\n",
        "  # if np.any((unq > 1) | (unq < 0)):\n",
        "    # print(col, \" - \", x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_FdCs_evJnC",
        "outputId": "24912155-7c31-47bc-abf2-00b103e8d27f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(26216, 39)\n"
          ]
        }
      ],
      "source": [
        "# the rows deleted that had a value of 2\n",
        "print(df_binary_check.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cwpZUdfudmPU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "id                        0\n",
              "message                   0\n",
              "genre                     0\n",
              "related                   0\n",
              "request                   0\n",
              "offer                     0\n",
              "aid_related               0\n",
              "medical_help              0\n",
              "medical_products          0\n",
              "search_and_rescue         0\n",
              "security                  0\n",
              "military                  0\n",
              "child_alone               0\n",
              "water                     0\n",
              "food                      0\n",
              "shelter                   0\n",
              "clothing                  0\n",
              "money                     0\n",
              "missing_people            0\n",
              "refugees                  0\n",
              "death                     0\n",
              "other_aid                 0\n",
              "infrastructure_related    0\n",
              "transport                 0\n",
              "buildings                 0\n",
              "electricity               0\n",
              "tools                     0\n",
              "hospitals                 0\n",
              "shops                     0\n",
              "aid_centers               0\n",
              "other_infrastructure      0\n",
              "weather_related           0\n",
              "floods                    0\n",
              "storm                     0\n",
              "fire                      0\n",
              "earthquake                0\n",
              "cold                      0\n",
              "other_weather             0\n",
              "direct_report             0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# drop the nulls from the dataframe\n",
        "df.isna().sum()\n",
        "# we noted that there are no null values in the dataframe, we have had removed the duplicates earier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "CYOxlkBBejH3"
      },
      "outputs": [],
      "source": [
        "# X = df[df.columns[3:]]\n",
        "# y = df['message']\n",
        "\n",
        "X = df['message']\n",
        "y = df[df.columns[3:]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNLX0hAEe_CV",
        "outputId": "3b794901-bc21-4ea7-8ff0-711ec142cc8c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(26028, 36)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2zsvNNkQhUWv"
      },
      "source": [
        "### Pipeline Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Rmxvp6u0481s"
      },
      "outputs": [],
      "source": [
        "# define the machine learning pipeline\n",
        "pipeline = Pipeline(\n",
        "    [\n",
        "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
        "        ('tfidf', TfidfTransformer()),\n",
        "        ('classifier', (RandomForestClassifier(n_jobs=-1)))\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "rCH_HPMzOLZN"
      },
      "outputs": [],
      "source": [
        "# split the data in training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=11, train_size=.8)\n",
        "\n",
        "# y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOwaxqx8PB36",
        "outputId": "0d467882-edeb-43d1-8319-6a0c4550ff8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('vect',\n",
              "                 CountVectorizer(tokenizer=<function tokenize at 0x0000027046246F70>)),\n",
              "                ('tfidf', TfidfTransformer()),\n",
              "                ('classifier', RandomForestClassifier(n_jobs=-1))])"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fit the model in pipeline took 9.46 min\n",
        "pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXJPSQ98hW7M"
      },
      "source": [
        "### Prediction Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_r_SgkxwQNOT"
      },
      "outputs": [],
      "source": [
        "# predict the test data took 34 sec\n",
        "y_pred = pipeline.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZO8GmF4ZTYc-",
        "outputId": "6359702a-c235-48f8-8ac3-36f0128bc573"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5206, 36), (5206, 36), 36)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# test shape of the outcome\n",
        "\n",
        "y_pred.shape, y_test.shape, len(list(df.columns[3:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efFbOLNvQmfe",
        "outputId": "4d5d5235-5b62-4797-cb69-d3d9c08773d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy -  related                   0.830964\n",
            "request                   0.896658\n",
            "offer                     0.996350\n",
            "aid_related               0.771802\n",
            "medical_help              0.916827\n",
            "medical_products          0.946408\n",
            "search_and_rescue         0.972724\n",
            "security                  0.982520\n",
            "military                  0.970419\n",
            "child_alone               1.000000\n",
            "water                     0.952171\n",
            "food                      0.930081\n",
            "shelter                   0.929889\n",
            "clothing                  0.986362\n",
            "money                     0.978294\n",
            "missing_people            0.986554\n",
            "refugees                  0.966769\n",
            "death                     0.954668\n",
            "other_aid                 0.878602\n",
            "infrastructure_related    0.931233\n",
            "transport                 0.954476\n",
            "buildings                 0.947945\n",
            "electricity               0.980023\n",
            "tools                     0.994814\n",
            "hospitals                 0.987130\n",
            "shops                     0.995198\n",
            "aid_centers               0.988667\n",
            "other_infrastructure      0.953131\n",
            "weather_related           0.858240\n",
            "floods                    0.940453\n",
            "storm                     0.930657\n",
            "fire                      0.989243\n",
            "earthquake                0.957933\n",
            "cold                      0.977142\n",
            "other_weather             0.948137\n",
            "direct_report             0.868037\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# check accuracy of your model\n",
        "acc = (y_pred == y_test).mean()\n",
        "print(\"Accuracy - \", acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa6L8OTyRSUj",
        "outputId": "9b50dedd-0929-4bbe-a6d3-5666025b48ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                        precision    recall  f1-score   support\n",
            "\n",
            "               related       0.86      0.93      0.89      3922\n",
            "               request       0.83      0.49      0.62       881\n",
            "                 offer       0.00      0.00      0.00        19\n",
            "           aid_related       0.81      0.58      0.67      2135\n",
            "          medical_help       0.85      0.02      0.05       442\n",
            "      medical_products       0.80      0.04      0.08       288\n",
            "     search_and_rescue       0.47      0.05      0.09       141\n",
            "              security       0.00      0.00      0.00        88\n",
            "              military       0.45      0.03      0.06       153\n",
            "           child_alone       0.00      0.00      0.00         0\n",
            "                 water       0.88      0.28      0.42       328\n",
            "                  food       0.87      0.45      0.59       589\n",
            "               shelter       0.85      0.24      0.38       457\n",
            "              clothing       0.79      0.14      0.24        79\n",
            "                 money       1.00      0.03      0.07       117\n",
            "        missing_people       0.00      0.00      0.00        70\n",
            "              refugees       0.67      0.02      0.04       175\n",
            "                 death       0.65      0.06      0.11       243\n",
            "             other_aid       0.72      0.05      0.09       651\n",
            "infrastructure_related       0.00      0.00      0.00       354\n",
            "             transport       0.50      0.02      0.03       237\n",
            "             buildings       0.69      0.03      0.06       276\n",
            "           electricity       1.00      0.01      0.02       105\n",
            "                 tools       0.00      0.00      0.00        27\n",
            "             hospitals       0.00      0.00      0.00        67\n",
            "                 shops       0.00      0.00      0.00        24\n",
            "           aid_centers       0.00      0.00      0.00        59\n",
            "  other_infrastructure       0.00      0.00      0.00       241\n",
            "       weather_related       0.85      0.57      0.69      1406\n",
            "                floods       0.88      0.32      0.47       426\n",
            "                 storm       0.77      0.32      0.45       466\n",
            "                  fire       0.50      0.02      0.03        56\n",
            "            earthquake       0.90      0.60      0.72       466\n",
            "                  cold       0.50      0.01      0.02       119\n",
            "         other_weather       0.50      0.01      0.02       270\n",
            "         direct_report       0.80      0.39      0.52       969\n",
            "\n",
            "             micro avg       0.84      0.47      0.60     16346\n",
            "             macro avg       0.54      0.16      0.21     16346\n",
            "          weighted avg       0.76      0.47      0.52     16346\n",
            "           samples avg       0.66      0.43      0.47     16346\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\thr3e\\anaconda3\\envs\\gurus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\thr3e\\anaconda3\\envs\\gurus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\thr3e\\anaconda3\\envs\\gurus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "C:\\Users\\thr3e\\anaconda3\\envs\\gurus\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# print the classification report\n",
        "class_rept = classification_report(y_test, y_pred, target_names=df.columns[3:])\n",
        "print(class_rept)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export the pipeline as a model\n",
        "pickle.dump(pipeline, open('random_forest_model.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Use GridSearch to improve the model\n",
        "we ll use grid search to find better parameters. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pipeline = Pipeline(\n",
        "#     [\n",
        "#         ('vect', CountVectorizer(tokenizer=tokenize)),\n",
        "#         ('tfidf', TfidfTransformer()),\n",
        "#         ('classifier', MultiOutputClassifier(RandomForestClassifier()))\n",
        "#     ]\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters = {\n",
        "#     'vect__ngram_range': ((1, 1), (1, 2)),\n",
        "#     'vect__max_df': (0.5, 0.75, 1.0),\n",
        "#     'vect__max_features': (None, 5000, 10000),\n",
        "#     'tfidf__use_idf': (True, False),\n",
        "#     'tfidf__sublinear_tf': (True, False),\n",
        "#     'classifier__estimator__n_estimators': (200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000),\n",
        "#     'classifier__estimator__bootstrap': (True, False),\n",
        "#     'classifier__estimator__max_depth': (10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None),\n",
        "#     'classifier__estimator__max_features': ('auto', 'sqrt'),\n",
        "#     'classifier__estimator__min_samples_leaf': (1, 2, 4),\n",
        "#     'classifier__estimator__min_samples_split': (2, 5, 10)\n",
        "# }\n",
        "\n",
        "parameters = {'clf__estimator__max_features':['sqrt', 0.5],\n",
        "              'clf__estimator__n_estimators':[50, 100]}\n",
        "\n",
        "cv = GridSearchCV(estimator=pipeline, param_grid = parameters, cv = 5, n_jobs = -1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['cv', 'error_score', 'estimator__memory', 'estimator__steps', 'estimator__verbose', 'estimator__vect', 'estimator__tfidf', 'estimator__classifier', 'estimator__vect__analyzer', 'estimator__vect__binary', 'estimator__vect__decode_error', 'estimator__vect__dtype', 'estimator__vect__encoding', 'estimator__vect__input', 'estimator__vect__lowercase', 'estimator__vect__max_df', 'estimator__vect__max_features', 'estimator__vect__min_df', 'estimator__vect__ngram_range', 'estimator__vect__preprocessor', 'estimator__vect__stop_words', 'estimator__vect__strip_accents', 'estimator__vect__token_pattern', 'estimator__vect__tokenizer', 'estimator__vect__vocabulary', 'estimator__tfidf__norm', 'estimator__tfidf__smooth_idf', 'estimator__tfidf__sublinear_tf', 'estimator__tfidf__use_idf', 'estimator__classifier__bootstrap', 'estimator__classifier__ccp_alpha', 'estimator__classifier__class_weight', 'estimator__classifier__criterion', 'estimator__classifier__max_depth', 'estimator__classifier__max_features', 'estimator__classifier__max_leaf_nodes', 'estimator__classifier__max_samples', 'estimator__classifier__min_impurity_decrease', 'estimator__classifier__min_samples_leaf', 'estimator__classifier__min_samples_split', 'estimator__classifier__min_weight_fraction_leaf', 'estimator__classifier__n_estimators', 'estimator__classifier__n_jobs', 'estimator__classifier__oob_score', 'estimator__classifier__random_state', 'estimator__classifier__verbose', 'estimator__classifier__warm_start', 'estimator', 'n_jobs', 'param_grid', 'pre_dispatch', 'refit', 'return_train_score', 'scoring', 'verbose'])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv.get_params().keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=12)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "cv.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = cv.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(classification_report(y_test, y_pred, target_names=y.columns))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pickle.dump(pipeline, open('random_forest_model_improved.pkl', 'wb'))\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Disaster Response_ML Pipeline Preperation.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "e4a9a4e7e54c057812c33e73b7e0ec4a73d994e132fdd5933feef9e932b3e01e"
    },
    "kernelspec": {
      "display_name": "Python 3.8.11 64-bit ('dl4cv': virtualenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
